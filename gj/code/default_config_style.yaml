network: "Attention"
input_size:
  height: 128
  width: 128
SATRN:
  encoder:
    hidden_dim: 300
    filter_dim: 600
    layer_num: 6
    head_num: 8
  decoder:
    src_dim: 300
    hidden_dim: 128
    filter_dim: 512
    layer_num: 3
    head_num: 8
Attention:
  src_dim: 512
  hidden_dim: 128
  embedding_dim: 128
  layer_num: 1
  cell_type: "LSTM"
checkpoint: ""
log_dir: /opt/ml/code/code/src/log


########################### NAME 
prefix: attention_50

data:
  train: # "/opt/ml/input/data/train_dataset/gt.txt"
    - "/opt/ml/input/data/train_dataset/split_gt/gt_s:0_l:1.txt"
    - "/opt/ml/input/data/train_dataset/split_gt/gt_s:0_l:2.txt"
    - "/opt/ml/input/data/train_dataset/split_gt/gt_s:0_l:3.txt"
    - "/opt/ml/input/data/train_dataset/split_gt/gt_s:0_l:4.txt"
    - "/opt/ml/input/data/train_dataset/split_gt/gt_s:0_l:5.txt"
    - "/opt/ml/input/data/train_dataset/split_gt/gt_s:1_l:1.txt"
    - "/opt/ml/input/data/train_dataset/split_gt/gt_s:1_l:2.txt"
    - "/opt/ml/input/data/train_dataset/split_gt/gt_s:1_l:3.txt"
    - "/opt/ml/input/data/train_dataset/split_gt/gt_s:1_l:4.txt"

  test:
    - ""
  token_paths:
    - "/opt/ml/input/data/train_dataset/tokens.txt"  # 241 tokens
  dataset_proportions:  # proportion of data to take from train (not test)
    - 1.0
  random_split: True # if True, random split from train files
  test_proportions: 0.2 # only if random_split is True
  crop: True
  rgb: 1    # 3 for color, 1 for greyscale
  use_small_data: False # {False |  True}
  
batch_size: 96
num_workers: 8
num_epochs: 50
print_epochs: 1
save_type: best # no_save: dont save, best: save best 1
use_amp: True
dropout_rate: 0.1
teacher_forcing_ratio: 0.5
max_grad_norm: 2.0
seed: 1234
optimizer:
  encoder:
    type: 'AdamP' # Adam, AdamW Adadelta, AdamP, SGDP
    lr: 5e-4 # 1e-4
    weight_decay: 1e-4
    is_cycle: True
  decoder:
    type: 'AdamW' # Adam, AdamW, Adadelta, AdamP, SGDP
    lr: 5e-4 # 1e-4
    weight_decay: 1e-4
    is_cycle: True
    
use_log_type: wandb # null, tensorboard, wandb # not using tensorboard
wandb:
  project: ocr
  entity: rolypolyvg295
  tags: 
    - v0
    - ocr
    - baseline

  ######################### NAME 
  name: attention_base # null: use prefix instead

