{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da115edf-38c2-4eee-962e-acbeb212225b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/ml/team/gj/code\n"
     ]
    }
   ],
   "source": [
    "%cd ../code/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "959054d7-61e1-4ff2-856f-994c11002f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import math\n",
    "from attrdict import AttrDict\n",
    "\n",
    "from dataset import (\n",
    "    dataset_loader, SizeBatchSampler, split_gt, load_levels, load_sources, load_vocab, encode_truth\n",
    ")\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b2d3ef5c-3cc9-47e4-96ee-cae5924e96aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy  dummy_2\teval_dataset  out_stuff  saving_model  train_dataset\n"
     ]
    }
   ],
   "source": [
    "!ls /opt/ml/input/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "09c5bec1-4887-4837-834a-54f2c30bfdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/opt/ml/input/data/train_dataset'\n",
    "image_root = f'{root}/images'\n",
    "source_f = open(f'{root}/source.txt')\n",
    "sources = [line.strip().split('\\t') for line in source_f.readlines()]\n",
    "sources = [(x, int(y)) for x, y in sources]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "76f2b86a-f26e-4f59-a1a9-dbbf8a66a401",
   "metadata": {},
   "outputs": [],
   "source": [
    "level_f = open(f'{root}/level.txt')\n",
    "levels = [line.strip().split('\\t') for line in level_f.readlines()]\n",
    "levels = [(x, int(y)) for x, y in levels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7bfc9d86-0125-4cce-b272-0d4b77a5b7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_f = open(f'{root}/gt.txt')\n",
    "gts = [line.strip().split('\\t') for line in gt_f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b90dcc00-c05e-48da-8278-10ca823f917e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 100000, 100000)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sources_df = pd.DataFrame(sources, columns=['path', 'source'])\n",
    "gts_df = pd.DataFrame(gts, columns=['path', 'gt'])\n",
    "levels_df = pd.DataFrame(levels, columns=['path', 'level'])\n",
    "\n",
    "len(sources_df), len(gts_df), len(levels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5515bf2a-0a82-4ea4-b8ad-1f33732f6165",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = sources_df.merge(levels_df).merge(gts_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a29969b-460b-4f43-ac08-5a298387bd0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c4ed72e8-28ef-411b-87bb-1bef85a96883",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \"\"\"Load Dataset\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        groundtruth,\n",
    "        tokens_file,\n",
    "        levels,\n",
    "        sources,\n",
    "        crop=False,\n",
    "        transform=None,\n",
    "        rgb=3,\n",
    "        max_resolution=128*128,\n",
    "        is_flexible=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            groundtruth (string): Path to ground truth TXT/TSV file\n",
    "            tokens_file (string): Path to tokens TXT file\n",
    "            ext (string): Extension of the input files\n",
    "            crop (bool, optional): Crop images to their bounding boxes [Default: False]\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        super(CustomDataset, self).__init__()\n",
    "        self.crop = crop\n",
    "        self.transform = transform\n",
    "        self.rgb = rgb\n",
    "        self.token_to_id, self.id_to_token = load_vocab(tokens_file)\n",
    "        self.data = [\n",
    "            {\n",
    "                \"path\": p,\n",
    "                \"truth\": {\n",
    "                    \"text\": truth,\n",
    "                    \"encoded\": [\n",
    "                        self.token_to_id[START],\n",
    "                        *encode_truth(truth, self.token_to_id),\n",
    "                        self.token_to_id[END],\n",
    "                    ],\n",
    "                    'rotated': idx%4,\n",
    "                    'flipped': idx%2,\n",
    "                },\n",
    "            }\n",
    "            for idx, (p, truth) in enumerate(groundtruth)\n",
    "        ]\n",
    "\n",
    "        for datum in self.data:\n",
    "            file_path = datum['path'].split('/')[-1]\n",
    "            source = sources.get(file_path, -100) # -100 crossentory 무시 index\n",
    "            level = levels.get(file_path, -99) - 1 # -100 모름\n",
    "            datum['source'] = source\n",
    "            datum['level'] = level\n",
    "\n",
    "        self.is_flexible = is_flexible\n",
    "        if self.is_flexible:\n",
    "            self.shape_cache = np.zeros((len(self), 2), dtype=int)\n",
    "            self.max_resolution = max_resolution\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        item = self.data[i]\n",
    "        image = Image.open(item[\"path\"])\n",
    "        if self.rgb == 3:\n",
    "            image = image.convert(\"RGB\")\n",
    "        elif self.rgb == 1:\n",
    "            image = image.convert(\"L\")\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if self.crop:\n",
    "            # Image needs to be inverted because the bounding box cuts off black pixels,\n",
    "            # not white ones.\n",
    "            bounding_box = ImageOps.invert(image).getbbox()\n",
    "            image = image.crop(bounding_box)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.is_flexible:\n",
    "            image = transforms.Resize(self.get_shape(i))(image)\n",
    "            \n",
    "            rot_idx = item['truth']['rotated']\n",
    "        flip_idx = item['truth']['flipped']\n",
    "        \n",
    "        angle = rot_idx * 90\n",
    "        image = transforms.functional.rotate(image, angle)\n",
    "        \n",
    "        if flip_idx == 1:\n",
    "            image = transforms.functional.hflip(image)\n",
    "\n",
    "        return {\n",
    "            \"path\": item[\"path\"],\n",
    "            \"truth\": item[\"truth\"],\n",
    "            \"image\": image,\n",
    "            'source': item['source'],\n",
    "            'level': item['level'],\n",
    "        }\n",
    "\n",
    "    def get_shape(self, i):\n",
    "        h, w = self.shape_cache[i]\n",
    "        if h == 0 and w == 0:\n",
    "            item = self.data[i]\n",
    "            image = Image.open(item[\"path\"])\n",
    "            rw, rh = image.size\n",
    "\n",
    "            T = self.max_resolution\n",
    "            div = rw * rh / T\n",
    "            w = round(rw/math.sqrt(div))\n",
    "            h = round(rh/math.sqrt(div))\n",
    "            w = round(w / 32) * 32\n",
    "            h = T // w\n",
    "            # h = (T // w) // 32 * 32\n",
    "\n",
    "            self.shape_cache[i][0] = h\n",
    "            self.shape_cache[i][1] = w\n",
    "        return h, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2f186432-8fb5-4eef-a2f2-bfc306b60dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_batch(data):\n",
    "    max_len = max([len(d[\"truth\"][\"encoded\"]) for d in data])\n",
    "    # Padding with -1, will later be replaced with the PAD token\n",
    "    padded_encoded = [\n",
    "        d[\"truth\"][\"encoded\"] + (max_len - len(d[\"truth\"][\"encoded\"])) * [-1]\n",
    "        for d in data\n",
    "    ]\n",
    "    return {\n",
    "        \"path\": [d[\"path\"] for d in data],\n",
    "        \"image\": torch.stack([d[\"image\"] for d in data], dim=0),\n",
    "        \"truth\": {\n",
    "            \"text\": [d[\"truth\"][\"text\"] for d in data],\n",
    "            \"encoded\": torch.tensor(padded_encoded), \n",
    "            'rotated': torch.tensor([d['truth']['rotated'] for d in data]),\n",
    "            'flipped': torch.tensor([d['truth']['flipped'] for d in data]),\n",
    "        },\n",
    "        'level': torch.tensor([d['level'] for d in data], dtype=torch.long),\n",
    "        'source': torch.tensor([d['source'] for d in data], dtype=torch.long),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1fc272be-7dd9-4c06-9ec2-3559bb0b7e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = AttrDict(\n",
    "    input_size=AttrDict(\n",
    "        height=128,\n",
    "        width=128\n",
    "    ),\n",
    "    data=AttrDict(\n",
    "        flexible_image_size=True,\n",
    "        random_split=0.2,\n",
    "        train=[\"/opt/ml/input/data/train_dataset/gt.txt\"],\n",
    "        test_proportions=0.2,\n",
    "        dataset_proportions=[1],\n",
    "        use_small_data=False,\n",
    "        token_paths=[\"/opt/ml/input/data/train_dataset/tokens.txt\"],\n",
    "        source_paths=[\"/opt/ml/input/data/train_dataset/source.txt\"],\n",
    "        level_paths=[\"/opt/ml/input/data/train_dataset/level.txt\"],\n",
    "        crop= True,\n",
    "        rgb=1,\n",
    "    ),\n",
    "    batch_size=16,\n",
    "    num_workers=8,\n",
    ")\n",
    "\n",
    "# transformed = transforms.Compose(\n",
    "#     [\n",
    "#         transforms.ToTensor(),\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "\n",
    "# train_data_loader, validation_data_loader, train_dataset, valid_dataset = dataset_loader(options, transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3b3dfb10-6812-4921-a718-3eb529f21f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Test Data Loading\n",
      "Random Split 0.2\n",
      "From /opt/ml/input/data/train_dataset/gt.txt\n",
      "Prop: 1\tTrain +: 80000\tVal +: 20000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e8ca7e33cf4a93b08c84df19f8b5f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "510bcc45f49e474dac3db722f30341b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "START = \"<SOS>\"\n",
    "END = \"<EOS>\"\n",
    "PAD = \"<PAD>\"\n",
    "SPECIAL_TOKENS = [START, END, PAD]\n",
    "\n",
    "\n",
    "train_data, valid_data = [], [] \n",
    "if options.data.random_split:\n",
    "    print('Train-Test Data Loading')\n",
    "    print(f'Random Split {options.data.test_proportions}')\n",
    "    for i, path in enumerate(options.data.train):\n",
    "        prop = 1.0\n",
    "        if len(options.data.dataset_proportions) > i:\n",
    "            prop = options.data.dataset_proportions[i]\n",
    "        train, valid = split_gt(path, prop, options.data.test_proportions)\n",
    "        train_data += train\n",
    "        valid_data += valid\n",
    "        print(f'From {path}')\n",
    "        print(f'Prop: {prop}\\tTrain +: {len(train)}\\tVal +: {len(valid)}')\n",
    "else:\n",
    "    print('Train Data Loading')\n",
    "    for i, path in enumerate(options.data.train):\n",
    "        prop = 1.0\n",
    "        if len(options.data.dataset_proportions) > i:\n",
    "            prop = options.data.dataset_proportions[i]\n",
    "        train = split_gt(path, prop)\n",
    "        train_data += train\n",
    "        print(f'From {path}')\n",
    "        print(f'Prop: {prop}\\tVal +: {len(train)}')\n",
    "\n",
    "    print()\n",
    "    print('Test Data Loading')\n",
    "    for i, path in enumerate(options.data.test):\n",
    "        valid = split_gt(path)\n",
    "        valid_data += valid\n",
    "        print(f'From {path}')\n",
    "        print(f'Val +:\\t{len(valid)}')\n",
    "\n",
    "# Load data\n",
    "if options.data.use_small_data:\n",
    "    old_train_len = len(train_data)\n",
    "    old_valid_len = len(valid_data)\n",
    "    train_data = train_data[:100]\n",
    "    valid_data = valid_data[:10]\n",
    "    print(\"Using Small Data\")\n",
    "    print(f\"Train: {old_train_len} -> {len(train_data)}\")\n",
    "    print(f'Valid: {old_valid_len} -> {len(valid_data)}')\n",
    "\n",
    "levels = load_levels(options.data.level_paths)\n",
    "sources = load_sources(options.data.source_paths)\n",
    "\n",
    "train_dataset = CustomDataset(\n",
    "    train_data, options.data.token_paths, sources=sources,\n",
    "    levels=levels, crop=options.data.crop,\n",
    "    transform=transformed, rgb=options.data.rgb,\n",
    "    max_resolution=options.input_size.height * options.input_size.width,\n",
    "    is_flexible=options.data.flexible_image_size,\n",
    ")\n",
    "\n",
    "valid_dataset = CustomDataset(\n",
    "    valid_data, options.data.token_paths, sources=sources,\n",
    "    levels=levels, crop=options.data.crop,\n",
    "    transform=transformed, rgb=options.data.rgb,\n",
    "    max_resolution=options.input_size.height * options.input_size.width,\n",
    "    is_flexible=options.data.flexible_image_size,\n",
    ")\n",
    "\n",
    "if options.data.flexible_image_size:\n",
    "    train_sampler = SizeBatchSampler(train_dataset, options.batch_size, is_random=True)\n",
    "    train_data_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_sampler=train_sampler,\n",
    "        num_workers=options.num_workers,\n",
    "        collate_fn=collate_batch,\n",
    "    )\n",
    "\n",
    "    valid_sampler = SizeBatchSampler(valid_dataset, options.batch_size, is_random=False)\n",
    "    valid_data_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_sampler=valid_sampler,\n",
    "        num_workers=options.num_workers,\n",
    "        collate_fn=collate_batch,\n",
    "    )\n",
    "else:\n",
    "    train_data_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=options.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=options.num_workers,\n",
    "        collate_fn=collate_batch,\n",
    "    )\n",
    "\n",
    "    valid_data_loader = DataLoader(\n",
    "        valid_dataset,\n",
    "        batch_size=options.batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=options.num_workers,\n",
    "        collate_fn=collate_batch,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bf3aff2e-74b2-465d-93a2-d1bcccd16c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = merged.groupby(['source', 'level'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6e954e68-88a4-4543-8cfc-441628e07a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty source: 1 level: 5\n"
     ]
    }
   ],
   "source": [
    "for source in range(2):\n",
    "    for level in range(1, 5 + 1):\n",
    "        try:\n",
    "            g = groups.get_group((source, level))\n",
    "            g.loc[:, ['path', 'gt']].to_csv(\n",
    "                f'gt_s:{source}_l:{level}.txt',\n",
    "                sep='\\t',\n",
    "                header=False,\n",
    "                index=False,\n",
    "                quoting=csv.QUOTE_NONE,\n",
    "            )\n",
    "        except KeyError:\n",
    "            print(f'Empty source: {source} level: {level}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "fbf197bf-8547-45d5-8415-cd4f38f18eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>gt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th>level</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>1</th>\n",
       "      <td>3748</td>\n",
       "      <td>3748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32288</td>\n",
       "      <td>32288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9236</td>\n",
       "      <td>9236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4156</td>\n",
       "      <td>4156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>572</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">1</th>\n",
       "      <th>1</th>\n",
       "      <td>9753</td>\n",
       "      <td>9753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11242</td>\n",
       "      <td>11242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24548</td>\n",
       "      <td>24548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4457</td>\n",
       "      <td>4457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               path     gt\n",
       "source level              \n",
       "0      1       3748   3748\n",
       "       2      32288  32288\n",
       "       3       9236   9236\n",
       "       4       4156   4156\n",
       "       5        572    572\n",
       "1      1       9753   9753\n",
       "       2      11242  11242\n",
       "       3      24548  24548\n",
       "       4       4457   4457"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups.count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
