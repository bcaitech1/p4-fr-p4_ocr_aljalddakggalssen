적극적으로 개입하여 수정한 부분이 이정도라 이정도만 올려둔다. X(  
# Inference.py  
## Rotation  
torch.rot90 이라는 고마운 애가 찾으면 금방 나와서 써부럿다. 차원을 지정해서 돌려줄 수도 있어서 편했던거 같다. batch랑 언제쯤 친해질까.  
장점 : 너무나도 뻔하게 회전되어 있는 이미지들에 대해서는 성능이 절륜했다. 절대적인 성능이 아니라 비교를 하면 더욱 티가 난다.  
![image](https://user-images.githubusercontent.com/73811730/122445420-81a8a500-cfdc-11eb-85fc-8011814c4454.png)

  
기존 결과 : 29	train_00029.jpg	f _ { { } } { { { { { { } { { } { { } { } { } { } { } { } { } { } } { } } { } } } { } } } }   
회전 결과 : 29	train_00029.jpg	a = \sqrt { a _ { 1 } ^ { 2 } + a _ { 2 } ^ { 2 } } = \sqrt { \left( \left( 9 0 0 \right) ^ ^ { 2 } + \left( 0 0 0 0 ^ { } } } } } 2 } m } } } 	14.944093704223633  
후자의 정확도가 훌륭하다고는 말 할 수 없지만, 기존 결과가 좀 더 후진 버전이긴 하지만 숫자를 하나도 못뽑은거에 비하면 진짜 발전 많이했다.  

## Score + reason  
근데 69를 구분 못하더라. 숫자 8이나 곱셈같은 기호는 뒤집어놔서 의미를 유지하거나, 다른 유효한 기호로 인식되기도 했다.  
그래서 :  
1. 점수가 높은 애가 등장하면 교체 할 것.  
2. 단, 기존(무회전) 의 점수결과가 일정 수치 이하일 때(못미더울 때) 에만 바꿔주는 조건을 달았다. 앵간하면 이미지가 정방향으로 제시 될 때가 많으니, 그 때의 점수 영역을 파악하자  


++ 안타깝게도 1&2번의 조합은 서버가 많이 아파서 점수 확인을 못했다  

# train.py  
## DIY  
teacher forcing ratio : 학습중 GT를 얼마나 알려줄지 비율을 정한다.  
높으면 정답 의존적이 되지만 inference가 단축되어 학습 시간이 줄어든다.  
낮으면 독립적이고 똘똘한 아이가 되지만 학습 시간도 길어지고 학습 효율도 구리다.  

그래서 scheduling을 도입했는데, 이게 맞는건가 싶었다. 초반에 높게, 후반에 낮게 한다면 epoch이 증가할수록 머리아파진다.  
총 epoch이 커지면 초반에 불필요하게 긴 시간을 답지를 보고 학습하게 될거고, 반대로 epoch이 짧으면 학습을 다 하기도 전에 답지를 뺏는거다.  
여기서 출발한 아이디어가 총 epoch에 따라 다른 스케줄링을 적용 할 바에는, 그 원인이라고 볼 수 있는 성능 기반의 scheduling을 하자.
1-accuracy를 TFR로 주어서, 성능이 좋아질수록 어려운 자습을 하게 했다. 특정 지점(0.4~0.6)에서 학습이 더뎌지기도 했는데, 보조바퀴를 떼는 과도기를 지나니 다시 성능이 잘 올랐다.
